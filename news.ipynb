{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def fetch_news_article(api_key):\n",
        "    url = f'https://newsapi.org/v2/top-headlines?sources=bbc-news&apiKey={api_key}'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        articles = response.json().get('articles')\n",
        "        if articles:\n",
        "            return articles[0].get('content')\n",
        "    return None\n",
        "\n",
        "# Replace 'your_api_key' with your actual News API key\n",
        "api_key = 'cb57ae0383eb47e4a541cbe063ae62ad'\n",
        "article = fetch_news_article(api_key)\n",
        "print(\"Article:\\n\", article)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJTilkgeUrMM",
        "outputId": "6e267822-77c3-4c4d-8162-7e03c5dbbdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article:\n",
            " The World Anti-Doping Agency (Wada) says it is \"unfairly caught\" in a row between the US and China, with their geopolitical tensions spilling onto the Olympic stage. \r\n",
            "China's top swimmers have been â€¦ [+1809 chars]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def extract_entities_spacy(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "spacy_entities = extract_entities_spacy(article)\n",
        "print(\"Entities from spaCy:\\n\", spacy_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBvP1fwYMHn",
        "outputId": "26c47bc2-1513-42e1-c181-933ff0377425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities from spaCy:\n",
            " [('The World Anti-Doping Agency', 'ORG'), ('Wada', 'GPE'), ('US', 'GPE'), ('China', 'GPE'), ('Olympic', 'LOC'), ('China', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "def extract_entities_nltk(text):\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "    nltk.download('words')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    entities = []\n",
        "    for sentence in sentences:\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        tags = nltk.pos_tag(words)\n",
        "        tree = nltk.ne_chunk(tags, binary=False)\n",
        "        for subtree in tree:\n",
        "            if isinstance(subtree, nltk.Tree):\n",
        "                entity = \" \".join([word for word, tag in subtree.leaves()])\n",
        "                entity_type = subtree.label()\n",
        "                entities.append((entity, entity_type))\n",
        "    return entities\n",
        "\n",
        "nltk_entities = extract_entities_nltk(article)\n",
        "print(\"Entities from NLTK:\\n\", nltk_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78erMHBqY45m",
        "outputId": "70ff983f-dd9e-4f7c-f42a-75020d353002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities from NLTK:\n",
            " [('Wada', 'ORGANIZATION'), ('US', 'ORGANIZATION'), ('China', 'GPE'), ('China', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_entities(spacy_entities, nltk_entities):\n",
        "    spacy_set = set(spacy_entities)\n",
        "    nltk_set = set(nltk_entities)\n",
        "\n",
        "    common = spacy_set & nltk_set\n",
        "    spacy_unique = spacy_set - nltk_set\n",
        "    nltk_unique = nltk_set - spacy_set\n",
        "\n",
        "    print(\"Common Entities:\\n\", common)\n",
        "    print(\"\\nEntities unique to spaCy:\\n\", spacy_unique)\n",
        "    print(\"\\nEntities unique to NLTK:\\n\", nltk_unique)\n",
        "\n",
        "compare_entities(spacy_entities, nltk_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeteU542Y9g6",
        "outputId": "b82ad63e-e759-436c-e3ff-407d344f4ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common Entities:\n",
            " {('China', 'GPE')}\n",
            "\n",
            "Entities unique to spaCy:\n",
            " {('Olympic', 'LOC'), ('US', 'GPE'), ('Wada', 'GPE'), ('The World Anti-Doping Agency', 'ORG')}\n",
            "\n",
            "Entities unique to NLTK:\n",
            " {('Wada', 'ORGANIZATION'), ('US', 'ORGANIZATION')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEK_EZumZtAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}